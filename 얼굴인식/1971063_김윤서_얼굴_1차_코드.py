# -*- coding: utf-8 -*-
"""얼굴인식1차_김윤서.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18lkym4HJp7kC6ENyjGO2aPHLrd_x78i-

# 생체인증보안 얼굴인식 과제 1
1971063 김윤서

## 0. 필요한 라이브러리 불러오기
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib
# %matplotlib inline
import matplotlib.pyplot as plt
import os
import cv2
from os.path import isfile, join
import glob
import gzip
from PIL import Image
from scipy import misc

import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.preprocessing.image import array_to_img

# CNN
import keras
from keras.models import Sequential
from keras.models import load_model
from keras.utils.np_utils import to_categorical
from keras.models import Model
from keras import layers, regularizers, optimizers, callbacks
from collections import defaultdict
from keras.optimizers import RMSprop
from keras.layers.normalization import BatchNormalization

"""## 1. 전처리 """

#데이터 불러오기

def create_Trainset(folder):
   
    img_data_array=[]
    class_name=[]
    
    for file in os.listdir(folder):
        image_path = os.path.join(folder, file)
        image = load_img(image_path, 'rb')
        image = img_to_array(image)
        
        if image.shape[2] == 3:
            image = image.mean(2)

        img_data_array.append(image)
        name_index = file.split("_")
        name_index = int(name_index[0])
        class_name.append(name_index)
        
    return np.array(img_data_array), np.array(class_name)


def create_Testset(folder):
   
    img_data_array=[]
    class_name=[]
    
    for file in os.listdir(folder):
        image_path = os.path.join(folder, file)
        image = load_img(image_path, 'rb')
        image = img_to_array(image)
        
        if image.shape[2] == 3:
            image = image.mean(2)

        img_data_array.append(image)
        name_index = file.split(".")
        name_index = int(name_index[0])
        class_name.append(name_index)
        
    return np.array(img_data_array), np.array(class_name)

# 정규화
def normalization(image):  
    image = image / image.max()
    return image

train_PATH = '/content/drive/MyDrive/face-training-set'
x_train, y_train = create_Trainset(train_PATH) #불러오기
x_train = normalization(x_train) # 정규화 진행

test_PATH = '/content/drive/MyDrive/face-test-set'
x_test, _ = create_Testset(test_PATH)
x_test = normalization(x_test)

### 첫번째 데이터 출력해보기
img1 = matplotlib.image.imread(join('/content/drive/MyDrive/face-training-set/0001_0001.BMP'))
plt.figure()
plt.figure(figsize=(24,25))
plt.subplot(1,5,1, facecolor='w')
plt.imshow(img1, cmap='gray')

print('Train images :',x_train.shape)
print('Train labels : ', y_train.shape)
print('Test images : ', x_test.shape)

"""### test 데이터프레임 만들기"""

test_index = os.listdir(test_PATH)
temp = []

for index in test_index:
    index = index.split(".")
    temp.append(int(index[0]))
    
test_index = temp

"""## 2. CNN 모델 정의

relu, softmax 활성화 함수 이용
"""

# 이전 코드 삭제 (함수형으로 변경)

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(56, 46)),
    keras.layers.Dense(256, activation='relu'),
    keras.layers.Dense(351, activation='softmax')
])

# loss 함수로 sparse_categorical_crossentropy 사용
model.compile(loss='sparse_categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

model.summary()   # 모델 확인하기

"""## 3. 모델 학습시키기"""

model.fit(x_train, y_train, epochs=30)
#model.fit(x_train, y_train, epochs = 50)

"""## 4. 학습시킨 모델 검증"""

x_predict = model.predict(x_train)
y_predict = []

print(x_predict.shape)

for image in x_predict:
    y_predict.append(np.argmax(image))

y_predict = np.array(y_predict)

def accuracy(original, x_predict):
    accuracy = original == x_predict
    accuracy = np.count_nonzero(accuracy)
    
    return accuracy / original.shape[0]
    

accuracy(y_train, y_predict)  #모델의 정확도 출력

"""## 5. 성능 개선
epoch 변경
## 6. 모델을 이용해 Test set을 예측 -> .csv 로 저장
"""

# test
predictions = model.predict(x_test)  #test데이터의 Y-test 예측하기
print(predictions.shape)

y_test = []
for image in predictions:
    y_test.append(np.argmax(image))

y_test = np.array(y_test)

#결과
print(y_test)

### csv 저장

test_result_df = pd.DataFrame([x for x in zip(test_index, y_test)], columns=['Image', 'Answer'])
test_result_df.head()

test_result_df = test_result_df.sort_values(by="Image")
test_result_df.head()

test_result_df.to_csv("/content/drive/MyDrive/hw2-1-result.csv", index=False)
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "final_project_김윤서-복사본.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1c101413308b4e8491c22547ae3067d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_437e189f0d624cbb965fcf849e030d29",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_39e471020e614dbc8566013a1c1b0e41",
              "IPY_MODEL_12a77198f8024ab192b8e5e66c530535"
            ]
          }
        },
        "437e189f0d624cbb965fcf849e030d29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39e471020e614dbc8566013a1c1b0e41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_14bac94685924e0d97df35ed6176b10f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5deedd99a9ea480a97d98322030eac0d"
          }
        },
        "12a77198f8024ab192b8e5e66c530535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_688104df288546e89b2b10d77f47308a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:02&lt;00:00, 61841246.55it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd5d0ad91975454894e9496d7f8a6580"
          }
        },
        "14bac94685924e0d97df35ed6176b10f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5deedd99a9ea480a97d98322030eac0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "688104df288546e89b2b10d77f47308a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd5d0ad91975454894e9496d7f8a6580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OwMXaL2WEB9"
      },
      "source": [
        "# **ML Final Project**\n",
        "### 1971063 김윤서   \n",
        "\n",
        "• Task 1: Implement Inception module for CIFAIR-10. (20 points)    \n",
        "• Task 2: Increase your Test set accuracy. (25 points)    \n",
        "• Task 3: Find hyper-parameters. (25 points)    \n",
        "• Task 4: Write report: (30 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU2Dql1UI5sn"
      },
      "source": [
        "## 0. CIFAR10 데이터셋 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeLry21NI5so"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1ZAvf3wI5sr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "1c101413308b4e8491c22547ae3067d2",
            "437e189f0d624cbb965fcf849e030d29",
            "39e471020e614dbc8566013a1c1b0e41",
            "12a77198f8024ab192b8e5e66c530535",
            "14bac94685924e0d97df35ed6176b10f",
            "5deedd99a9ea480a97d98322030eac0d",
            "688104df288546e89b2b10d77f47308a",
            "fd5d0ad91975454894e9496d7f8a6580"
          ]
        },
        "outputId": "8b02fcd4-5eba-4527-8e76-f309b01b2ee5"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        " #train data 용도\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,   \n",
        "                                        download=True, transform=transform) \n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size= 8,          #hyper-parameter: batch_size=8\n",
        "                                          shuffle=True, num_workers=2)\n",
        "  \n",
        "  #test data 용도\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,    \n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size= 8,            #hyper-parameter: batch_size=8\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c101413308b4e8491c22547ae3067d2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52Y715_6u7Z3",
        "outputId": "b4d9ffc1-a4c6-4737-d2f0-db86d8e082e8"
      },
      "source": [
        "print(trainset)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            "           )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZYnQFOt7dHe"
      },
      "source": [
        "## 1. 필요한 함수 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvx_B_5_-QBG"
      },
      "source": [
        "#### train_val 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPjez6P_8GOZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "de2ad07b-2217-49a4-af7b-f04b0ac36686"
      },
      "source": [
        "\n",
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "\n",
        "\n",
        "def metric_batch(output, target):\n",
        "    pred = output.argmax(dim=1, keepdim=True)\n",
        "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "    return corrects\n",
        "\n",
        "\n",
        "\n",
        "def loss_batch(loss_func, outputs, target, opt=None):\n",
        "    if np.shape(outputs)[0] == 3:\n",
        "        output, aux1, aux2 = outputs\n",
        "\n",
        "        output_loss = loss_func(output, target)\n",
        "        aux1_loss = loss_func(aux1, target)\n",
        "        aux2_loss = loss_func(aux2, target)\n",
        "\n",
        "        loss = output_loss + 0.3*(aux1_loss + aux2_loss)\n",
        "        metric_b = metric_batch(output,target)\n",
        "\n",
        "    else:\n",
        "        loss = loss_func(outputs, target)\n",
        "        metric_b = metric_batch(outputs, target)\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    \n",
        "    return loss.item(), metric_b\n",
        "\n",
        "\n",
        "\n",
        "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
        "    running_loss = 0.0\n",
        "    running_metric = 0.0\n",
        "    len_data = len(dataset_dl.dataset)\n",
        "\n",
        "    for xb, yb in dataset_dl:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        output= model(xb)\n",
        "\n",
        "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
        "\n",
        "        running_loss += loss_b\n",
        "\n",
        "        if metric_b is not None:\n",
        "            running_metric += metric_b\n",
        "        \n",
        "        if sanity_check is True:\n",
        "            break\n",
        "\n",
        "    loss = running_loss / len_data\n",
        "    metric = running_metric / len_data\n",
        "\n",
        "    return loss, metric\n",
        "\n",
        "\n",
        "\n",
        "def train_val(model, params):\n",
        "    num_epochs=params[\"num_epochs\"]\n",
        "    loss_func=params[\"loss_func\"]\n",
        "    opt=params[\"optimizer\"]\n",
        "    train_dl=params[\"train_dl\"]\n",
        "    val_dl=params[\"val_dl\"]\n",
        "\n",
        "    loss_history = {'train': [], 'val': []}\n",
        "    metric_history = {'train': [], 'val': []}\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    \n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        current_lr = get_lr(opt)\n",
        "        print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs - 1, current_lr))\n",
        "        \n",
        "        model.train()\n",
        "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
        "        loss_history['train'].append(train_loss)\n",
        "        metric_history['train'].append(train_metric)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            torch.save(model.state_dict(), path2weights)\n",
        "            print('Copied best model weights!')\n",
        "\n",
        "        loss_history['val'].append(val_loss)\n",
        "        metric_history['val'].append(val_metric)\n",
        "\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "        print('-'*10)\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, loss_history, metric_history"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5f3d9a0bf63b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStepLR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UyuRKiD8dvE"
      },
      "source": [
        "#### 시각화 함수: learning curve 그리기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIYo9mOUV7Wu"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_acc(history, title=None):\n",
        "  # summarize history for accuracy\n",
        "  if not isinstance(history, dict):\n",
        "    history = history.history\n",
        "  plt.plot(history['accuracy'])         # train 데이터로 구한 정확도값\n",
        "  plt.plot(history['val_accuracy'])     # test 데이터로 구한 정확도값\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Training', 'Test'], loc=0)   # 두 선의 이름(Train, Test) 표시\n",
        "\n",
        "def plot_loss(history, title=None):\n",
        "  # summarize history for loss\n",
        "  if not isinstance(history, dict):\n",
        "    history = history.history\n",
        "  plt.plot(history['loss'])             # train 데이터로 구한 손실값\n",
        "  plt.plot(history['val_loss'])         # test 데이터로 구한 손실값\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Training', 'Test'], loc=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajkWIeGS8RRb"
      },
      "source": [
        "+ 데이터셋 확인해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57_tR3K6I5sx"
      },
      "source": [
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# print size of single image\n",
        "print(images[1].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfZ0paa1I5s0"
      },
      "source": [
        "## 2. Inception module 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6cRUzgCRGYX"
      },
      "source": [
        "class Inception(nn.Module):\n",
        "    def __init__(self, in_planes, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes):\n",
        "        super(Inception, self).__init__()\n",
        "        # 1x1 conv branch\n",
        "        self.b1 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, n1x1, kernel_size=1),\n",
        "            nn.BatchNorm2d(n1x1),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        # 1x1 conv -> 3x3 conv branch\n",
        "        self.b2 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, n3x3red, kernel_size=1),\n",
        "            nn.BatchNorm2d(n3x3red),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(n3x3red, n3x3, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n3x3),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        # 1x1 conv -> 5x5 conv branch\n",
        "        self.b3 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, n5x5red, kernel_size=1),\n",
        "            nn.BatchNorm2d(n5x5red),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(n5x5red, n5x5, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(n5x5),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(n5x5, n5x5, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(n5x5),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        # 3x3 pool -> 1x1 conv branch\n",
        "        self.b4 = nn.Sequential(\n",
        "            nn.MaxPool2d(3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n",
        "            nn.BatchNorm2d(pool_planes),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.b1(x)\n",
        "        y2 = self.b2(x)\n",
        "        y3 = self.b3(x)\n",
        "        y4 = self.b4(x)\n",
        "        return torch.cat([y1,y2,y3,y4], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq5CBG3FYgEv"
      },
      "source": [
        "## 3. CNN 모델 정의 \n",
        "#### Training setup:\n",
        "* Loss function: Sotfmax cross entropy\n",
        "* Optimizer: Gradient descent with 0.001 learning rate\n",
        "* Batch size: 4\n",
        "* Training epoch: 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvPD_kEt87f2"
      },
      "source": [
        "### 모델 1: GoogleNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMQV21XUTchi"
      },
      "source": [
        "# Training on GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wZwraFTT2em"
      },
      "source": [
        "### 모델 2: GoogleNet 보완해보기 -> MyNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm7Q5UirTnvx"
      },
      "source": [
        "\n",
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "\n",
        "        self.pre_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 128, kernel_size=3, padding=1),  #hyper-Parameter: filter size = 3\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),        #활성화 함수 ReLU 사용\n",
        "        )\n",
        "\n",
        "        self.a3 = Inception(128,  32,  48,  64,  8, 16, 16)\n",
        "        self.b3 = Inception(128,  64,  96, 128, 16, 32, 32)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        self.a4 = Inception(256, 160,  96, 256, 16,  64,  64)\n",
        "        self.b4 = Inception(544, 256, 128, 256, 64, 128, 128)\n",
        "        self.c4 = Inception(768, 256, 128, 256, 64, 128, 128)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        self.a5 = Inception(768, 256, 256, 512, 64, 128, 128)\n",
        "        self.b5 = Inception(1024, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(8, stride=1)  # Average Pooling 사용\n",
        "        self.linear = nn.Linear(1024, 10)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        out = self.pre_layers(x)\n",
        "        out = self.a3(out)\n",
        "        out = self.b3(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.a4(out)\n",
        "        out = self.b4(out)\n",
        "        out = self.c4(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.a5(out)\n",
        "        out = self.b5(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o16jluaJTxLo"
      },
      "source": [
        "\n",
        "myNet = MyNet()\n",
        "myNet = myNet.to(device)\n",
        "\n",
        "# Define a Loss function and optimizer\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(myNet.parameters(), lr=0.0005, momentum=0.9)\n",
        "\n",
        "PATH = './my_net.pth'\n",
        "epochs = 6\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY0bapFABxEF"
      },
      "source": [
        "params_train = {\n",
        "    'num_epochs':epochs,\n",
        "    'optimizer':optimizer,\n",
        "    'loss_func':loss_func,\n",
        "    'train_dl':trainloader,\n",
        "    'val_dl':testloader\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj0x9hMo8dhV"
      },
      "source": [
        "\n",
        "model, loss_hist, metric_hist = train_val(model, params_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntC8TOhBT0qU"
      },
      "source": [
        "plot_loss(metric_hist)\n",
        "plt.show()\n",
        "\n",
        "plot_acc(metric_hist)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9cXDiqslfiQ"
      },
      "source": [
        "## * hyper-parameter 목록\n",
        "1. **learning rate** (lr)=0.001, 0.0005, 0.0001, ...   \n",
        "2. **Batch size**=4,8,16,32   \n",
        "3. **Epochs**=2,4, ...\n",
        "4. Network architectures: googLeNet\n",
        "5. Activation functions: RELU 사용   \n",
        "6. Loss function: Sotfmax cross entropy   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1PJK2zdmLd3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}